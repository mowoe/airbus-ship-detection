{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airbus_Ship_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "SDd-Ssrp2W0J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "import time\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CNQbkqrpXRLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iYEnNL90hsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras\n",
        "!pip install mrcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QRzQXrFGWYar",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qx4_aKtB2dy6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "key = input(\"Please put your Kaggle credentials in JSON format in\")\n",
        "with open(\"kaggle.json\", \"w\") as f:\n",
        "    f.write(key) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RbiASJ6Cm-jE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ROOT_DIR = os.path.abspath(\"/content/\")\n",
        "root_dir = \"/content/\"\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"/content/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SaLoFNwr5aga",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lWrhAbSf5jq7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "!kaggle competitions download airbus-ship-detection\n",
        "print(\"downloading dataset took {} seconds\".format(time.time()-start))\n",
        "download_spent = time.time() - start"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c2aMWKAtL5sj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "force = False #@param {type:\"boolean\"}\n",
        "if download_spent > 50 or force == True:\n",
        "  for file in [root_dir+\"test_v2.zip\",root_dir+\"train_ship_segmentations_v2.csv.zip\",root_dir+\"train_v2.zip\"]:\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()\n",
        "      print(file)\n",
        "else:\n",
        "  print(\"Not unzipping because old dataset is still present, use force=True to stil unzip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uuSsHlL2_pbr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8svJ8Hw3C7D6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c73U9wc3LmO2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(root_dir+\"train_ship_segmentations_v2.csv\").dropna()\n",
        "df.index = np.arange(0, len(df))\n",
        "display(df[:10])\n",
        "print(df.ImageId[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ozRVF8FgTBJ3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "def masks_as_image(in_mask_list, all_masks=None):\n",
        "    # Take the individual ship masks and create a single mask array for all ships\n",
        "    if all_masks is None:\n",
        "        all_masks = np.zeros((768, 768), dtype = np.int16)\n",
        "    #if isinstance(in_mask_list, list):\n",
        "    for mask in in_mask_list:\n",
        "        if isinstance(mask, str):\n",
        "            all_masks += rle_decode(mask)\n",
        "    return np.expand_dims(all_masks, -1)\n",
        "  \n",
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def rle_decode(mask_rle, shape=(768, 768)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T  # Needed to align to RLE direction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XWvKrkUZx_35",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OjEwyOnUlUNh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "only_ships_df = df[df.EncodedPixels.isnull()==False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q5yTezOsYh7y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShipsDatasetOne(mrcnn.utils.Dataset):\n",
        "  def load_dataset(self, dataset_frame, width, height):\n",
        "    self.dataset_frame = dataset_frame\n",
        "    self.add_class(\"ships\", 1, \"ship\")\n",
        "    count = 0\n",
        "    for x in tqdm(dataset_frame.ImageId.unique()):\n",
        "      ships = []\n",
        "      for b in range(len(df.query('ImageId==\"'+x+'\"')['EncodedPixels'])):\n",
        "        ships.append(\"ship\")\n",
        "      self.add_image(\"ships\", image_id=count, path=x,\n",
        "                    width=width, height=height,\n",
        "                    ships=ships)\n",
        "      count+=1\n",
        "      \n",
        "  \n",
        "  def load_image(self,image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    if info[\"id\"] == image_id:\n",
        "      ships = info['ships']\n",
        "      filename = info['path']\n",
        "      image = cv2.imread(root_dir+filename)\n",
        "      return image\n",
        "    else:\n",
        "      print(\"FATAL ERROR! NOT MATHCING IDs\")\n",
        "  \n",
        "  def load_mask(self,image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    assert info[\"id\"] == image_id\n",
        "    ships = info['ships']\n",
        "    filename = info['path']\n",
        "    rle_0 = df.query('ImageId==\"'+filename+'\"')['EncodedPixels']\n",
        "    mask = masks_as_image(rle_0) \n",
        "    class_ids = np.array([self.class_names.index(s) for s in ships])\n",
        "    if len(class_ids) != 0:\n",
        "      class_ids = np.array([1])\n",
        "    return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "  \n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info['ships']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Df5N06_q3b6G",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_train = ShipsDatasetOne()\n",
        "dataset_train.load_dataset(only_ships_df[:20000],768,768)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9EIalOly4u8u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_val = ShipsDatasetOne()\n",
        "dataset_val.load_dataset(only_ships_df[-1000:],768,768)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qJM_93wNV4kH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_val.prepare()\n",
        "dataset_train.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDidM118dWb2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###I  really dont know what the  problem was, but somehow np.unique([1]) != np.unique([1,1,1,1]), when using it for indexing of an ndarray\n",
        "So i fixed it with:\n",
        "\n",
        "\n",
        "```\n",
        "if len(class_ids) != 0:\n",
        "      class_ids = np.array([1])\n",
        " ```\n",
        "Which just sets the class_ids to the shape of (1,) when the old shape is bigger than (0,)\n",
        "\n",
        "So [1,1,1,1,1,1] -> [1]\n",
        "\n",
        "This is not an issue because there is only class Id: 1 because we are only detecting ships, nothing else.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rxl-4GSM4MHS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "print(image_ids)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EmbG7T1o2wyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShapesConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"ships\"\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 4\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # background + 3 ships\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 768\n",
        "    IMAGE_MAX_DIM = 768\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 2500\n",
        "\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 10\n",
        "    \n",
        "config = ShapesConfig()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PpNMPwbymzfq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gnw1vRu7n7n9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # @param [\"imagenet\", \"coco\", \"last\"]\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    !wget -O mask_rcnn_coco.h5 https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "    COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fR7NEpB9XxGs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jilVeHGr3MRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers#to train by name pattern.\n",
        "train = True # @param {type:'boolean'}\n",
        "if train:\n",
        "  model.train(dataset_train, dataset_val, \n",
        "              learning_rate=config.LEARNING_RATE, \n",
        "              epochs=1, \n",
        "              layers='heads')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UyZCWU1uczD5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if train:\n",
        "  model.train(dataset_train, dataset_val, \n",
        "              learning_rate=config.LEARNING_RATE / 10,\n",
        "              epochs=1, \n",
        "              layers=\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWAa5sZr5lNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(\"mask_rcnn_ships.h5\")\n",
        "model.keras_model.save_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l2Xi-y-mwkdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = True #@param {type:\"boolean\"}\n",
        "if download:\n",
        "  from google.colab import files\n",
        "  files.download('mask_rcnn_ships.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZAYNp0t3l8d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "upload  = False #@param {type:\"boolean\"}\n",
        "if upload:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60yW6Rip-ezQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InferenceConfig(ShapesConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "model_path = os.path.join(ROOT_DIR, \"mask_rcnn_ships.h5\")\n",
        "#model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-QMJa5rCT8A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_id = random.choice(dataset_val.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \n",
        "                           image_id, use_mini_mask=False)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xlpe2WsyCsHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "print(r['masks'].shape)\n",
        "print(r['class_ids'])\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_val.class_names, r['scores'], ax=get_ax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09GZQkQJCzdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_ids = np.random.choice(dataset_val.image_ids, 50)\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_PeIEXmsF1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zohwvzXpHSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submit_df = pd.read_csv(root_dir+\"sample_submission_v2.csv\").dropna()\n",
        "submit_df.index = np.arange(0, len(df))\n",
        "display(submit_df[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HMu8jUvisuKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "finished_d = {'ImageId': [], 'EncodedPixels': []}\n",
        "finished_df = pd.DataFrame(data=finished_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GYhTivc0T19U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for image in tqdm(submit_df.ImageId):\n",
        "  img = cv2.imread(image)\n",
        "  results = model.detect([img], verbose=0)\n",
        "  r = results[0]\n",
        "  c = False\n",
        "  for x in range(len(r['class_ids'])):\n",
        "    rle_0 = rle_encode(r['masks'][:,:,x])\n",
        "    finished_df = finished_df.append({'ImageId': image, 'EncodedPixels': rle_0}, ignore_index=True)\n",
        "    c = True\n",
        "  if not c:\n",
        "    finished_df = finished_df.append({'ImageId': image, 'EncodedPixels': \"\"}, ignore_index=True)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9UzOb_xKxFCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "finished_df.to_csv('/content/submissions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Cb_4U3R1p-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c airbus-ship-detection -f s/content/submissions.csv -m \"Very first submission! \\o/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKARJNYdwOND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display(finished_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGoslk9SxmY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/submissions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sj-o4-Rm3fm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_images = [\"000155de5.jpg\"]\n",
        "for image in predict_images:\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
        "  img = cv2.imread(image)\n",
        "  all_masks = []\n",
        "  results = model.detect([img], verbose=0)\n",
        "  r = results[0]\n",
        "  for x in range(len(r['class_ids'])):\n",
        "    all_masks.append(r['masks'][:,:,x])\n",
        "  complete_mask = np.stack(all_masks, axis=2)\n",
        "  ax1.imshow(img)\n",
        "  ax1.set_title('Image')\n",
        "  ax2.set_title('Mask')\n",
        "  ax2.imshow(complete_mask[...,0], cmap='gray')\n",
        "  plt.show()\n",
        "  rle_0 = rle_encode(complete_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anpWHe9cpj4B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}