{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airbus Ship Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kaU1BJvCKvQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "287d7a52-b377-410e-9a35-567b3ba74e2f"
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K    3% |█                               | 10kB 13.3MB/s eta 0:00:01\r\u001b[K    6% |██                              | 20kB 2.0MB/s eta 0:00:01\r\u001b[K    9% |███▏                            | 30kB 2.3MB/s eta 0:00:01\r\u001b[K    13% |████▏                           | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 51kB 2.3MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 61kB 2.8MB/s eta 0:00:01\r\u001b[K    22% |███████▍                        | 71kB 2.9MB/s eta 0:00:01\r\u001b[K    26% |████████▍                       | 81kB 2.8MB/s eta 0:00:01\r\u001b[K    29% |█████████▍                      | 92kB 3.1MB/s eta 0:00:01\r\u001b[K    32% |██████████▌                     | 102kB 3.1MB/s eta 0:00:01\r\u001b[K    36% |███████████▌                    | 112kB 3.2MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 122kB 4.0MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 133kB 4.0MB/s eta 0:00:01\r\u001b[K    45% |██████████████▊                 | 143kB 5.2MB/s eta 0:00:01\r\u001b[K    49% |███████████████▊                | 153kB 4.9MB/s eta 0:00:01\r\u001b[K    52% |████████████████▊               | 163kB 4.3MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▉              | 174kB 4.7MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▉             | 184kB 5.7MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 194kB 5.7MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 204kB 5.4MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 215kB 4.8MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████         | 225kB 5.5MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▏       | 235kB 5.6MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 245kB 4.6MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 256kB 5.4MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▎    | 266kB 5.7MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▎   | 276kB 5.7MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▍  | 286kB 5.4MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▍ | 296kB 4.6MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 307kB 5.6MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 317kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.1.6\n",
            "    Uninstalling Keras-2.1.6:\n",
            "      Successfully uninstalled Keras-2.1.6\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-OLTTm_hsK7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1094
        },
        "outputId": "3f2749cb-03e3-480d-d466-025a0771a032"
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall mrcnn\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "!cd Mask_RCNN && python3 setup.py install"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mSkipping mrcnn as it is not installed.\u001b[0m\n",
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 893 (delta 0), reused 0 (delta 0), pack-reused 892\u001b[K\n",
            "Receiving objects: 100% (893/893), 113.29 MiB | 38.41 MiB/s, done.\n",
            "Resolving deltas: 100% (525/525), done.\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JiOnCAQYFI4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5209f6f-8a23-4a87-9f82-d85f8ab53f85"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/matterport/Mask_RCNN/master/mrcnn/model.py -O /usr/local/lib/python3.6/dist-packages/mrcnn/model.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mrcnn/model.py: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9JuzfpdhRNi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NOW RESTART RUNTIME!"
      ]
    },
    {
      "metadata": {
        "id": "SDd-Ssrp2W0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "712e4736-27af-4341-ad73-2820493c3599"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "import time\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import keras\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QRzQXrFGWYar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d7defbc-f25c-4f26-f24e-f10263edbe99"
      },
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "qx4_aKtB2dy6",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "ceba3adf-00df-4396-891c-a2e5facea40f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-72eebdd3-e79c-487b-8d65-31c1a0731dd4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-72eebdd3-e79c-487b-8d65-31c1a0731dd4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"pernelkanic\",\"key\":\"036cfdc2baea2fa58f51243e4b73b9af\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "RbiASJ6Cm-jE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ROOT_DIR = os.path.abspath(\"/content/\")\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaLoFNwr5aga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lWrhAbSf5jq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "a70441f1-87fe-47bc-8ce2-b96c34a1d729"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "!kaggle competitions download airbus-ship-detection\n",
        "print(\"downloading dataset took {} seconds\".format(time.time()-start))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission_v2.csv to /content\n",
            "\r  0% 0.00/274k [00:00<?, ?B/s]\n",
            "100% 274k/274k [00:00<00:00, 63.8MB/s]\n",
            "Downloading train_ship_segmentations_v2.csv.zip to /content\n",
            " 28% 5.00M/18.0M [00:00<00:00, 29.5MB/s]\n",
            "100% 18.0M/18.0M [00:00<00:00, 77.4MB/s]\n",
            "Downloading test_v2.zip to /content\n",
            "100% 2.12G/2.12G [00:20<00:00, 124MB/s]\n",
            "100% 2.12G/2.12G [00:20<00:00, 110MB/s]\n",
            "Downloading train_v2.zip to /content\n",
            "100% 26.4G/26.4G [04:18<00:00, 96.7MB/s]\n",
            "100% 26.4G/26.4G [04:18<00:00, 109MB/s] \n",
            "downloading dataset took 283.6509726047516 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c2aMWKAtL5sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a2ab21e0-8279-4d15-c65c-931c16aa0fc7"
      },
      "cell_type": "code",
      "source": [
        "for file in [\"/content/test_v2.zip\",\"/content/train_v2.zip\",\"/content/train_ship_segmentations_v2.csv.zip\"]:\n",
        "    zip_ref = zipfile.ZipFile(file, 'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()\n",
        "    print(file)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/test_v2.zip\n",
            "/content/train_v2.zip\n",
            "/content/train_ship_segmentations_v2.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uuSsHlL2_pbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c73U9wc3LmO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "c9f3e57b-f996-419c-a576-1e6e75709e88"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_ship_segmentations_v2.csv\").dropna()\n",
        "df.index = np.arange(0, len(df))\n",
        "display(df[:10])\n",
        "print(df.ImageId[0])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000155de5.jpg</td>\n",
              "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000194a2d.jpg</td>\n",
              "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000194a2d.jpg</td>\n",
              "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000194a2d.jpg</td>\n",
              "      <td>198320 10 199088 10 199856 10 200624 10 201392...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000194a2d.jpg</td>\n",
              "      <td>55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>000194a2d.jpg</td>\n",
              "      <td>254389 9 255157 17 255925 17 256693 17 257461 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00021ddc3.jpg</td>\n",
              "      <td>108287 1 109054 3 109821 4 110588 5 111356 5 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00021ddc3.jpg</td>\n",
              "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00021ddc3.jpg</td>\n",
              "      <td>74441 3 75207 5 75975 5 76743 5 77511 5 78280 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00021ddc3.jpg</td>\n",
              "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ImageId                                      EncodedPixels\n",
              "0  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
              "1  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
              "2  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...\n",
              "3  000194a2d.jpg  198320 10 199088 10 199856 10 200624 10 201392...\n",
              "4  000194a2d.jpg  55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...\n",
              "5  000194a2d.jpg  254389 9 255157 17 255925 17 256693 17 257461 ...\n",
              "6  00021ddc3.jpg  108287 1 109054 3 109821 4 110588 5 111356 5 1...\n",
              "7  00021ddc3.jpg  101361 1 102128 3 102896 4 103663 6 104430 9 1...\n",
              "8  00021ddc3.jpg  74441 3 75207 5 75975 5 76743 5 77511 5 78280 ...\n",
              "9  00021ddc3.jpg  74444 4 75212 4 75980 4 76748 4 77517 3 78285 ..."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "000155de5.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ozRVF8FgTBJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.util.montage import montage2d as montage\n",
        "\n",
        "def masks_as_image(in_mask_list, all_masks=None):\n",
        "    # Take the individual ship masks and create a single mask array for all ships\n",
        "    if all_masks is None:\n",
        "        all_masks = np.zeros((768, 768), dtype = np.int16)\n",
        "    #if isinstance(in_mask_list, list):\n",
        "    for mask in in_mask_list:\n",
        "        if isinstance(mask, str):\n",
        "            all_masks += rle_decode(mask)\n",
        "    return np.expand_dims(all_masks, -1)\n",
        "  \n",
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def rle_decode(mask_rle, shape=(768, 768)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T  # Needed to align to RLE direction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XWvKrkUZx_35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjEwyOnUlUNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "only_ships_df = df[df.EncodedPixels.isnull()==False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q5yTezOsYh7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShipsDatasetOne(mrcnn.utils.Dataset):\n",
        "  def load_dataset(self, dataset_frame, width, height):\n",
        "    self.dataset_frame = dataset_frame\n",
        "    self.add_class(\"ships\", 1, \"ship\")\n",
        "    count = 0\n",
        "    for x in tqdm(dataset_frame.ImageId.unique()):\n",
        "      ships = []\n",
        "      for b in range(len(df.query('ImageId==\"'+x+'\"')['EncodedPixels'])):\n",
        "        ships.append(\"ship\")\n",
        "      self.add_image(\"ships\", image_id=count, path=x,\n",
        "                    width=width, height=height,\n",
        "                    ships=ships)\n",
        "      count+=1\n",
        "      \n",
        "  \n",
        "  def load_image(self,image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    if info[\"id\"] == image_id:\n",
        "      ships = info['ships']\n",
        "      filename = info['path']\n",
        "      image = cv2.imread(\"/content/\"+filename)\n",
        "      return image\n",
        "    else:\n",
        "      print(\"FATAL ERROR! NOT MATHCING IDs\")\n",
        "  \n",
        "  def load_mask(self,image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    assert info[\"id\"] == image_id\n",
        "    ships = info['ships']\n",
        "    filename = info['path']\n",
        "    rle_0 = df.query('ImageId==\"'+filename+'\"')['EncodedPixels']\n",
        "    mask = masks_as_image(rle_0) \n",
        "    class_ids = np.array([self.class_names.index(s) for s in ships])\n",
        "    return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "  \n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    return info['ships']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "whrqKK6jPteO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShipsDataset(mrcnn.utils.Dataset):\n",
        "  def load_dataset(self, dataset_frame, width, height, count, start=0):\n",
        "    self.add_class(\"shapes\", 1, \"square\")\n",
        "    self.add_class(\"shapes\", 2, \"circle\")\n",
        "    self.add_class(\"shapes\", 3, \"triangle\")\n",
        "    dataset_frame.index = np.arange(0, count)\n",
        "    for i in range(start,count):\n",
        "      shapes = []\n",
        "      filename = dataset_frame.ImageId[i]\n",
        "      for b in range(len(df.query('ImageId==\"'+filename+'\"')['EncodedPixels'])):\n",
        "        shapes.append(\"square\")\n",
        "      self.add_image(\"shapes\", image_id=i, path=filename,\n",
        "                    width=width, height=height,\n",
        "                    shapes=shapes)\n",
        "      \n",
        "  \n",
        "  def load_image(self,image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    assert info[\"id\"] == image_id\n",
        "    filename = info['path']\n",
        "    image = cv2.imread(\"/content/\"+filename,0)\n",
        "    return image\n",
        "    \n",
        "  \n",
        "  def load_mask(self,image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    assert info[\"id\"] == image_id\n",
        "    shapes = info['shapes']\n",
        "    filename = info['path']\n",
        "    rle_0 = df.query('ImageId==\"'+filename+'\"')['EncodedPixels']\n",
        "    mask = masks_as_image(rle_0) \n",
        "    class_ids = np.array([self.class_names.index(s) for s in shapes])\n",
        "    return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "  \n",
        "  def image_reference(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    if info[\"source\"] == \"shapes\":\n",
        "        return info[\"shapes\"]\n",
        "    else:\n",
        "        super(self.__class__).image_reference(self, image_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Df5N06_q3b6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_train = ShipsDataset()\n",
        "dataset_train.load_dataset(only_ships_df[:1000],768,768,1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EIalOly4u8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_val = ShipsDataset()\n",
        "dataset_val.load_dataset(only_ships_df[-1000:],768,768,1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJM_93wNV4kH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_val.prepare()\n",
        "dataset_train.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3-OdPbUUeCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "80712250-bb0f-4c2a-ff25-41c69401b135"
      },
      "cell_type": "code",
      "source": [
        "print(dataset_val.class_ids)\n",
        "print(dataset_val.image_info[0])\n",
        "mask, class_ids = dataset_train.load_mask(0)\n",
        "print(class_ids)\n",
        "print(mask.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4f5ac4ac3424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_val' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rxl-4GSM4MHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "9af5735b-2446-4d8e-a830-0e8b55c1f842"
      },
      "cell_type": "code",
      "source": [
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-daf184f713b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvisualize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_top_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/visualize.py\u001b[0m in \u001b[0;36mdisplay_top_masks\u001b[0;34m(image, mask, class_ids, class_names, limit)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0munique_class_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     mask_area = [np.sum(mask[:, :, np.where(class_ids == i)[0]])\n\u001b[0;32m--> 292\u001b[0;31m                  for i in unique_class_ids]\n\u001b[0m\u001b[1;32m    293\u001b[0m     top_ids = [v[0] for v in sorted(zip(unique_class_ids, mask_area),\n\u001b[1;32m    294\u001b[0m                                     key=lambda r: r[1], reverse=True) if v[1] > 0]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/visualize.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0munique_class_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     mask_area = [np.sum(mask[:, :, np.where(class_ids == i)[0]])\n\u001b[0;32m--> 292\u001b[0;31m                  for i in unique_class_ids]\n\u001b[0m\u001b[1;32m    293\u001b[0m     top_ids = [v[0] for v in sorted(zip(unique_class_ids, mask_area),\n\u001b[1;32m    294\u001b[0m                                     key=lambda r: r[1], reverse=True) if v[1] > 0]\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 2 with size 1"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LnMhVXvZnHQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShapesConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"ships\"\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # background + 3 ships\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 768\n",
        "    IMAGE_MAX_DIM = 768\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 500\n",
        "\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = ShapesConfig()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpNMPwbymzfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c37956b6-1a8b-4875-9ad9-95038b2e6a99"
      },
      "cell_type": "code",
      "source": [
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e0b80d629844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = modellib.MaskRCNN(mode=\"training\", config=config,\n\u001b[0m\u001b[1;32m      2\u001b[0m                           model_dir=MODEL_DIR)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'modellib' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Gnw1vRu7n7n9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "dd972528-951a-4f9c-dd91-c979a9984bf9"
      },
      "cell_type": "code",
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # @param [\"imagenet\", \"coco\", \"last\"]\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    !wget -O mask_rcnn_coco.h5 https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "    COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-23 07:44:48--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181023T074448Z&X-Amz-Expires=300&X-Amz-Signature=2333ef4587cbc7a842b701c6dada902360953ec24d397f3a1bb08cca6d39351b&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-10-23 07:44:48--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181023T074448Z&X-Amz-Expires=300&X-Amz-Signature=2333ef4587cbc7a842b701c6dada902360953ec24d397f3a1bb08cca6d39351b&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.101.195\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.101.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  41.2MB/s    in 6.1s    \n",
            "\n",
            "2018-10-23 07:44:55 (40.6 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bkdZFDkYpCYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4980
        },
        "outputId": "7f761d6f-5747-4403-aa07-7b89af0ebad5"
      },
      "cell_type": "code",
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "model.train(dataset_train, dataset_test, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=1, \n",
        "            layers='heads')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/logs/ships20181023T0745/mask_rcnn_ships_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Error processing image {'id': 208, 'source': 'ships', 'path': '015d9f6b2.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 208, 'source': 'ships', 'path': '015d9f6b2.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 285, 'source': 'ships', 'path': '01c559b28.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 285, 'source': 'ships', 'path': '01c559b28.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 106, 'source': 'ships', 'path': '00aa60389.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 106, 'source': 'ships', 'path': '00aa60389.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 260, 'source': 'ships', 'path': '0198728be.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship', 'ship', 'ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 1ERROR:root:Error processing image {'id': 380, 'source': 'ships', 'path': 'ff052ec4e.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "\n",
            "ERROR:root:Error processing image {'id': 380, 'source': 'ships', 'path': 'ff052ec4e.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 112, 'source': 'ships', 'path': 'fd67d5e27.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 3 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 112, 'source': 'ships', 'path': 'fd67d5e27.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 3 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 260, 'source': 'ships', 'path': '0198728be.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship', 'ship', 'ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 463, 'source': 'ships', 'path': 'ff70a294e.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 463, 'source': 'ships', 'path': 'ff70a294e.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 127, 'source': 'ships', 'path': 'fd7bddb7f.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 127, 'source': 'ships', 'path': 'fd7bddb7f.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 155, 'source': 'ships', 'path': '0104ed53e.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 270, 'source': 'ships', 'path': '01ad35fcb.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship', 'ship', 'ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 155, 'source': 'ships', 'path': '0104ed53e.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 270, 'source': 'ships', 'path': '01ad35fcb.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship', 'ship', 'ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 5 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 267, 'source': 'ships', 'path': 'fe56a7b12.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 267, 'source': 'ships', 'path': 'fe56a7b12.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 162, 'source': 'ships', 'path': 'fdb66dbe0.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n",
            "ERROR:root:Error processing image {'id': 162, 'source': 'ships', 'path': 'fdb66dbe0.jpg', 'width': 768, 'height': 768, 'ships': ['ship', 'ship']}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1704, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\", line 1272, in load_image_gt\n",
            "    class_ids = class_ids[_idx]\n",
            "IndexError: boolean index did not match indexed array along dimension 0; dimension is 2 but corresponding boolean dimension is 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-1beb077ceb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             layers='heads')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m         )\n\u001b[1;32m   2354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,192,192,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node fpn_p3upsampled/ResizeNearestNeighbor}} = ResizeNearestNeighbor[T=DT_FLOAT, _class=[\"loc:@train...ighborGrad\"], align_corners=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fpn_p3add/add-3-0-TransposeNCHWToNHWC-LayoutOptimizer, fpn_p3upsampled/mul)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node proposal_targets/cond_2/Merge/_4837}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8779_proposal_targets/cond_2/Merge\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UyZCWU1uczD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}